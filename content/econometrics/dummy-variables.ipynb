{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "    <tr style=\"background-color: transparent;\"><td>\n",
    "        <img src=\"https://d8a-88.github.io/econ-fa19/assets/images/blue_text.png\" width=\"250px\" style=\"margin-left: 0;\" />\n",
    "    </td><td>\n",
    "        <p style=\"text-align: right; font-size: 12pt;\"><strong>Economic Models</strong>, Fall 2019<br>\n",
    "            Dr. Eric Van Dusen</p></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 12 - Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-muted\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why do we need dummary variables?**\n",
    "\n",
    "Two cases:\n",
    "\n",
    "* variable has non-numeric values, e.g. the `sex`, `education`, `marital_status` variables in `defaults`\n",
    "* variable has categorical numeric values, e.g. a Likert scale (1 to $n$ are possible values) or the `age` variable\n",
    "\n",
    "In the first case, the reason is obvious: How can we model a variable that has text as its value?\n",
    "\n",
    "In the second, the reason is more subtle. Let's build two models on data from a Likert scale with values 1 to 7. The first model will leave the values as-is, and the second will use dummy variables for each possible value of the variable.\n",
    "\n",
    "In this section, we'll use a completely **deterministic** model, wherein $y$ will be a nonlinear function of $x$, with a bit of randomness introduced in the model constants. Our function for $y$ will be\n",
    "\n",
    "$$\\Large \n",
    "f(x) = a e^x + bx + c\n",
    "$$\n",
    "\n",
    "with $a,b \\sim U(0, 100)$ for each value of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    a = np.random.uniform(0, 100, len(x))\n",
    "    b = np.random.uniform(0, 100, len(x))\n",
    "    c = np.random.uniform(0, 100, len(x))\n",
    "    return a * np.exp(x) + b * x + c\n",
    "\n",
    "x = np.random.choice(np.arange(1, 8), 1000)\n",
    "y = f(x)\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build an OLS model based on `x` and `y` _without_ creating dummies for $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat_1 = sm.OLS(y, sm.add_constant(x)).fit().fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE for this model is calculated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(mean_squared_error(y, y_hat))\n",
    "\n",
    "rmse(y, y_hat_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some dummy variables for `x`; we'll store these in `X` (note the switch to capitals, since we are now in the multivariate case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(pd.DataFrame({\"x\" : x}), columns=[\"x\"]).values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit a model and look at our RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat_2 = sm.OLS(y, sm.add_constant(X)).fit().fittedvalues\n",
    "rmse(y, y_hat_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a drop in the RMSE when we use dummy variables for age because age is not a continuous variable, but a categorical one. With numerical categorical variables, values that are larger in magnitude that others cause greater shifts in model weights due only to their magnitude. This also helps to reveal nonlinear patterns between variables and a categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Get Dummy Variables for a Table\n",
    "\n",
    "You may have noticed that the code above uses the library `pandas`, which you will learn about in Data 100. However, if we want to use the `datascience` library, we need to define our own function to create dummy variables. Let's start by thinking about the intuition of creating dummy variables using a one-column table with only two possible values: `H` or `T`, for the flip of a coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flips = Table().with_column(\"flip\", np.random.choice([\"H\", \"T\"], 200))\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about our problem, what's the first thing that we need to know? I propose that we need to know all of the **unique** values of our variable, since we will need to create one new column for each of these. Although we already know our variable has only 2 possible values, \"H\" and \"T\", let's practice anyway. The function `np.unique` will give you an array of the unique values of the array passed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_vals = np.unique(flips.column(\"flip\"))\n",
    "unique_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know these values, we want to create a column for each value with a 1 if the value for that row equals the column value, and a 0 otherwise. To do this, we'll need to use a function that tells us if some value is equal to another pre-specified value. Luckily, you already know these! The predicate functions you use in `Table.where` will do this for us. So let's now look at how we can use these functions to create the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for val in unique_vals:\n",
    "    dummy_vals = flips.apply(are.equal_to(val), \"flip\")\n",
    "    flips = flips.with_column(\"flip_\" + val, dummy_vals)\n",
    "\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've created columns with names of the format `flips_{value}`. However, we still have a problem: these columns have boolean values, not integers!\n",
    "\n",
    "Recall now that we can **typecast** a `bool` to an `int` by calling the `int` function on it. This will map `True` to 1 and `False` to 0. Let's now do this with `Table.apply`. Notice in the cell below that we have added logic to apply this function to _our new columns_ using the format of their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for val in unique_vals:\n",
    "    int_vals = flips.apply(int, \"flip_\" + val)\n",
    "    flips = flips.with_column(\"flip_\" + val, int_vals)\n",
    "    \n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're almost there! The last thing we want to do is get rid of the original column, so that it doesn't muck up any analysis we do later on. Let's drop it with `Table.drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flips = flips.drop(\"flip\")\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've now created dummy variables for a categorical variable! Notice that our choice to iterate through the unique values means that we can use this same logic for any arbitrarily large number of unique values. The function `get_dummies` defined below encapsulates this logic that we've built, albeit with a simplified encoding step. This function will be provided for you in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dummies(tbl, col, drop=True):\n",
    "    \"\"\"Creates dummy variables for a column of a table\"\"\"\n",
    "    values = np.unique(tbl.column(col))\n",
    "    for val in values:\n",
    "        encoding = tbl.apply(lambda s: int(s == val), col)\n",
    "        tbl = tbl.with_column(col + \"_\" + str(val), encoding)\n",
    "    if drop:\n",
    "        tbl = tbl.drop(col)\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this function and its flexibility, let's imagine that we were rolling an icosahedron (a 20-sided die)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rolls = Table().with_column(\"roll\", np.random.choice(np.arange(1, 21), 400))\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_dummies(rolls, \"roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
